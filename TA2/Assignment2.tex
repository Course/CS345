\documentclass[11pt]{article}
\usepackage{latexsym}
\usepackage[vlined,ruled]{algorithm2e}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{epsfig}
\usepackage{psfrag}
\usepackage{color}
\input{rgb}
\newcommand{\handout}[5]{
  \noindent
  \begin{center}
  \framebox{
    \vbox{
      \hbox to 5.78in { {\bf CS345 : Algorithms II } \hfill #2 }
      \vspace{4mm}
      \hbox to 5.78in { {\Large \hfill #5  \hfill} }
      \vspace{2mm}
      \hbox to 5.78in { {\em #3 \hfill #4} }
    }
  }
  \end{center}
  \vspace*{4mm}
}

\newcommand{\lecture}[4]{\handout{#1}{#2}{#3}{}{#1}}


\newcommand{\TT}[1]{\textsc{#1}}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{proposition}[theorem]{Proposition}
%\newtheorem{problem}[theorem]{\color{darkred}{\bf Problem}}
\newtheorem{exercise}[theorem]{\color{DarkBlue}{\bf Exercise}}
\newtheorem{problem}[theorem]{\color{darkred}{\bf Problem}}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{assumption}[theorem]{Assumption}

\topmargin 0pt
\advance \topmargin by -\headheight
\advance \topmargin by -\headsep
\textheight 8.9in
\oddsidemargin 0pt
\evensidemargin \oddsidemargin
\marginparwidth 0.5in
\textwidth 6.5in

\parindent 0in
\parskip 1.5ex
\title{Assignment 2}
\author{Satvik Chauhan (Y9521),Pankaj More (Y9402)}
\begin{document}
\maketitle
\section*{Question 1}
Counter example for strategy 1 : \\
Highest deadline job has highest penalty . If it would have been scheduled earliest , it might not contribute to the penalty , but when it is scheduled last the set of valid time slots might have become nil. \\
Counter example for strategy 2: \\
Consider a case where the highest penalty job say $J_1$ is scheduled at earliest possible time slot say $t_1$ and it has more than one element in its set of valid time slots. It might block some other job $J_k$ whose set of valid time slots is exactly $t_1$. Then , $J_k$ would contribute to the total penalty whereas the optimal solution would not incur penalty from $J_k$.  \\
Formal Proof for strategy 3 : 
\begin{lemma}
Let $J_{1}$ be the job with highest penalty and $t_{1}$ is the latest time slot into which $J_{1}$ can be scheduled.
There exists an optimal solution in which $J_{1}$ is scheduled at slot $t_{1}$.
\end{lemma}
\begin{proof}
Let S* be any optimal solution. If S* schedules $J_{1}$ at $t_1$ , then we are done.\\
Otherwise , S* puts $J_1$ at some slot $t \neq t_1$ and puts some other job $j_k \neq j_1$ at slot $t_1$. \\
Consider a schedule S which differs from S* by exchanging the slots assigned to $j_k$ and $j_1$ while everything else is kept same. 
\begin{lemma}
S is an optimal solution
\end{lemma}
\begin{proof}
\begin{itemize}
\item Suppose $t_1 <= d_1$ and $J_1$ contributes no penalty in S*. Then $t < t_1$ , since $J_1$ can only be scheduled without penalty only in slots $<= t_1$ \\
Exchanging $J_k$ with $J_1$ does not introduce any penalty due to $J_1$.
Moreover , since $J_k$ moves to an earlier slot , its contribution to total penalty is either same or less than before. Hence , penalty(S) $<=$ penalty(S*)
\item Suppose $t_1 <= d_1$ and $J_1$ contributes its penalty in S*. Hence $t > t_1$. By exchanging , $J_k$ may contribute a penalty in S but $J_1$ will not. So , max(penalty(S)) $<=$ penalty(S*) + $p_k - p_1$ . Since , $p_1 <= p_k$ , penalty(S) $<=$ penalty(S*). 
\item Suppose $t_1 >= d_1$ . $J_1$ must contribute its penalty in every solution. Hence , by exchanging , we cannot eliminate the penalty of $J_1$ but the penalty due to $J_k$ might be eliminated.
Hence, penalty(S) $<=$ penalty(S*) 
\end{itemize}
In every possible case , penalty(S) $<=$ penalty(S*) . Hence , S is optimal.
\end{proof}
By using lemma 2 , we conclude the proof of lemma 1.
\end{proof}

\begin{lemma}
\[ 
 \vert Opt(A) \vert = \vert Opt(A\backslash(J_1,t_1)) \vert + p(J_1,t_1) 
\]
\end{lemma}
\begin{proof}
a) 
\[ 
 \vert Opt(A) \vert \leq \vert Opt(A\backslash(J_1,t_1)) \vert + p(J_1,t_1) 
\]
Adding $(J_1,t_1)$ to $Opt(A\backslash(J_1,t_1))$ gives us a valid schedule.\\
Hence , the optimal schedule will be at least as good as this vaild schedule. \\\\
b) \\
\[ 
\ \vert Opt(A\backslash(J_1,t_1)) \vert <= \vert Opt(A) \vert - p(J_1,t_1) 
\]
Using lemma 1 , there is an optimal solution containing $(J_1,t_1)$ .\\
Let that optimal solution be Opt(A). \\
Removing $(J_1,t_1)$ from Opt(A) gives us a valid schedule for $Opt(A\backslash(J_1,t_1))$ . \\
The optimal schedule will be at least as good as this vaild schedule. \\
\end{proof}
\begin{algorithm}[h]
$S\leftarrow \emptyset$\\
JL = List of Jobs sorted in non-increasing order of penalty $\backslash \backslash$ O(nlogn) \\
T = Height Balanced AVL Tree containing the time slots  using total order property of time-slots as key $\backslash \backslash$ O(nlogn) \\
\ForEach{$J \in JL$}{
	$l \leftarrow search(J.deadline,T)$ $\backslash \backslash$ O(logn) search returns the time slot with deadline preceding J.deadline in case of failure or max time slot in case no such deadline exists \\ 
	$S \leftarrow S \cup (J,l)$ \\
	$\backslash \backslash$ O(nlogn) \\
}	
return $S$
\caption{Algorithm for computing the optimal solution to the Job Scheduling Problem}
\label{skeleton}
\end{algorithm}
\pagebreak
\section*{Question 2}
Since $d(P_i,P_j) = d(P_j,P_i)$ for each point $P_i$ we insert $d(P_i,P_j)$ for all $j < i$. \\
Let this list be PL. \\
\begin{algorithm}[h]
$V\leftarrow \emptyset$\\
Sort PL in increasing order of distance. // O($n^2log(n)$) \\
\While{PL is not empty}{
Remove the first element from PL \;
Let d be the value of distance obtained in the first element \;
Let $P_i$ and $P_j$ be the end points of this element. \;
if $P_i$ in V and $P_j$ in V and $P_i$ and $P_j$ are not in the same subtree \\
Create an internal node of height = d\\
Assign its left child to the root of the subtree containing the leaf labelled $P_i$. \\ 
Assign its right child to the root of the subtree containing the leaf labelled $P_j$.\\ 

if $P_i$ in V and $P_j$ not in V \\
Create an internal node of height = d\\
Assign its left child to the root of the subtree containing the leaf labelled $P_i$.\\
Assign its right child to the leaf node (created if needed) with label $P_j$ and height 0 \\ 

if $P_i$ not in V and $P_j$ in V \\
Create an internal node of height = d\\
Assign its left child to the leaf node (created if needed) with label $P_i$ and height 0 \\
Assign its right child to the root of the subtree containing the leaf labelled $P_j$. \\

if $P_i$ not in V and $P_j$ not in V \\
Create an internal node of height = d\\
Assign its left child to the leaf node (created if needed) with label $P_i$ and height 0 \\
Assign its right child to the leaf node (created if needed) with label $P_j$ and height 0 \\

Whenever a leaf node is created , it is added to the set V \\

}

\caption{Algorithm for computing hierarchical metric}
\label{skeleton}
\end{algorithm}

Time Complexity : Since there are O($n^2$) iterations and each iteration takes polynomial time , hence the algorithm runs in polynomial time \\

Correctness : \\

h(v) = 0 for each leaf node v and h(u) $>=$ h(v) if u is parent of v \\

Whenever a new leaf node is created its height is set to 0 and the algorithm does not change it anywhere. \\
Observe that distances are added in increasing order to the tree . \\
So the height of an internal node is greater than its children (which were added to the tree before this iteration) \\


$\tau$ is consistent with d  :\\

Let $\tau$ be consistent with d after ith iteration. \\
If we can prove that $\tau$ is consistent with d after (i+1) iterations , then by induction theorem we are done. \\

In the ith iteration one of the following things can happen : - \\
\begin{itemize}
\item If the internal node created has two leaf nodes as its children  , its height is equal the distance between two children , hence it is consistent with d. \\
\item When both leaf nodes are already present in the same subtree , nothing changes . \\
\item When both leaf nodes are present in different subtrees , we create a new internal node and assign its height as the distance between these two leaf nodes . Since from the algorithm , this internal node is actually the least common ancestor of both the leaf nodes , $\tau$ is consistent with d \\
\item When one of the leaf nodes is not present in the tree , we create it with height 0. We assign it as the children of the new internal node . The root of the subtree containing other leaf node is also assigned as the children of this internal node. Since this internal node is the least common ancestor of the two , $\tau$ is consistent with d. \\

\end{itemize}

Since , $\tau$ is consistent with d at the end of (i+1) iterations , it also holds at the end of the algorithm .\\



If $\tau'$ is any other hierarchical metric consistent with d  then $\tau'(p_i,p_j) <= \tau(p_i,p_j) $ for all $p_i, p_j$ :\\

For all $p_i$ and $p_j$ , with $\tau(p_i,p_j) = d_{ij}$ no other $\tau'$ can be greater than $d_{ij}$ . Hence , $\tau'(p_i,p_j) <= \tau(p_i,p_j) $

Now we need to consider only those pair of points $p_i$ and $p_j$ , with $\tau(p_i,p_j) \neq d_{ij}$

Assume that for a particular value of $p_i$ and $p_j$ , $\tau'(p_i,p_j) > \tau(p_i,p_j)$  . \\
Let v be the least common ancestor in $\tau$ and v' in $\tau'$ . \\
$h(v) < h(v') <= d_{ij}$ \\
let the two nodes with $d_{xy}$ be $p_x$ and $p_y$. \\
Hence , $\tau'(p_x,p_y) = \tau'(p_i,p_j) > \tau(p_i,p_j) = \tau(p_x,p_y) = d_{xy} $ \\ 
But $\tau'(p_x,p_y) <= d_{xy} $ \\
Hence contradiction. 



\pagebreak
\section*{Question 3}
\begin{algorithm}[h]
$E'\leftarrow \emptyset$\;
\While{there is any vertex left in the graph}{
Pick any vertex $v$ arbitrarily\;
Grow a BFS tree starting from $v$, level by level, and stop as soon as \textbf{number of vertices on the last level $\leq$ total number of vertices till second last level * $n^{\frac{1}{k}}$}\;
$\backslash \backslash$ If bfs tree stops not because of above condition but because no more vertices then assume i = lastlevel + 1. So we will be adding all the edges of the bfs tree and removing all the vertices . \\
Let the BFS tree be grown to level $i$ in this manner\;
Add to $E'$ all those edges of the BFS tree upto level \textbf{i}\;
Remove all vertices of the BFS tree upto level \textbf{i-1} from the graph\;
}
return $(V,E')$\;
\caption{The skeleton of an Algorithm for computing $(2k-1)$-spanner of a graph $G$}
\label{skeleton}
\end{algorithm}
\begin{lemma}
The height of BFS tree can not be greater than  k.
\end{lemma}
\begin{proof}
If height of the tree becomes greater than k , it means at each level the number of vertices grow by a factor more than $n^{\frac{1}{k}}$. \\ 
Let $T(i)$ be the number of vertices till level $i$.
\begin{align*}
T(i) &> \underbrace{T(i-1)}_{\text{total vertices till level i-1}} + \underbrace{T(i-1)*(n^{\frac{1}{k}})}_{\text{vertices at level i}} \\
T(k) &> T(k-1) (1 + n^{\frac{1}{k}}) \\
	&= T(0) (1 + n^{\frac{1}{k}})^{k} \\
	&= (1 + n^{\frac{1}{k}})^{k} \\
	&> 1 + n 
\end{align*}
So bfs traversal stops before level k due to the following two cases
\begin{enumerate}
\item No more vertices to traverse in the bfs tree. 
\item We find a level i ($\leq k$) such that $T(i) - T(i-1) \leq n^\frac{1}{k}$ 
\end{enumerate}
\end{proof}
\begin{lemma}
For each edge removed there is a path of length $(2k-1)$ in the spanner. ($k>1$)
\end{lemma}
\begin{proof}
Since the height of bfs tree is never greater than k and any edge not present in the bfs tree is removed. \\
Let $v$ be the root of the tree and height of the bfs tree thus found be $l (\leq k)$.	 \\
Suppose the edge removed is $(x,y)$ . Then one of $x$ and $y$ should be at a level less than $i$ and other at a level less than or equal to $i$.\\
Without loss of generality let  level of $x$ be $p(< i)$ and level of $y$ be $q(\leq i)$ .  Then we need to show that there is a path from $x$ to $y$ of length not more than $2k-1$. \\
Consider the path from $x$ to $v$ to $y$ . Its length is 
\begin{align*}
length &= p+q \\
	&\leq (l-1) + l \\
	&\leq (k-1) + k \\
length	&\leq 2k -1
\end{align*}
So there exist a path from $x$ to $y$ of length $\leq$ 2k-1
\end{proof}
\begin{lemma} $\delta'(u,v) \le (2k-1) \delta(u,v) $
\end{lemma}
\begin{proof}
Consider the path from $u$ to $v$ in the old graph . Let it be 
\[ (u=x_1 , x_2 , \ldots , x_m=v)
\]
Proof by recursion on edges on the path \\
Base Case : $(u,v)$ is an edge then by previous lemma :
\[
\delta'(u,v) \leq (2k-1) \delta(u,v) 
\]
Induction : 
Let the number of edges on the path be w.
Now consider an edge between $x_1$ and $x_2$ . If it is not present in the spanner then by previous lemma we have a path of length less than (2k-1) between $x_1$ and $x_2$.  So 
\[\delta'(x_1,x_2) \leq (2k-1)
\]
\[
\delta'(u=x_1,v) = \delta'(x_1,x_2) +   \delta'(x_{2},v)
\]
\[
\delta'(u,v) \leq (2k-1) +   \delta'(x_{2},v)
\]
Since number of edges on the path $(x_{2},v)$ are less than w so using induction hypothesis :
\[
\delta'(u,v) \leq (2k-1) +   (2k-1)\delta(x_{2},v) 
\]
\[
\delta'(u,v) \le (2k-1) \delta(u,v) 
\]



\end{proof}
\begin{lemma}
Size of the spanner computed by the algorithm is $O(n^{1+1/k})$.
\end{lemma}
\begin{proof}
We are adding all the edges of the BFS tree upto level i-1 . The extra edges we are adding is less than  $T(i) * n^{\frac{1}{k}}$. \\
Now consider a BFS in which m vertices are removed after its completion. 
So edges added in the spanner due to this BFS is atmost
\begin{align*}
\underbrace{m}_{\text{bfs tree edges}} + \underbrace{m*n^{\frac{1}{k}}}_{\text{Extra edges added}}
\end{align*}
Consider all the BFS which algorithm runs and let $(m_1,m_2, \ldots m_p)$ be the vertices removed in each of them then 
$m_1 + m_2 + \ldots m_p = n$ as the vertices removed are disjoint and together they consist of the whole graph . \\
So total number of edges added are 
\begin{align*}
edges &< m_{1}  + m_{1}*n^\frac{1}{k} + m_{2}  + m_{2}*n^\frac{1}{k} + \ldots m_{p}  + m_{p}*n^\frac{1}{k} \\
&= (m_{1} + m_{2} + \ldots m_{p})*(1+n^{\frac{1}{k}})  \\
&= n*n^{\frac{1}{k}}  + n  \\
&= n^{1+\frac{1}{k}}  + n \\
&= O(n^{1+\frac{1}{k}})
\end{align*}
\end{proof}
\pagebreak
\section*{Question 4}
\begin{lemma}
Any edge of the graph (This does not include the edges added because of new vertex .) which is not present in the old MST is also not present in the new MST. 
\end{lemma}
\begin{proof}
Suppose (x,y) is an edge which is not present in the old MST. So if we include (x,y) in the old MST we get a cycle . Now if we remove the maximum weight edge of the  cycle we must get a MST again . If this maximum weight   edge is not (x,y) then the weight of the tree after its removal will decrease as compared to MST in which (x,y) was not present and hence contradiction . We keep on adding these edges and every time we form a cycle of which this edge is the maximum weight edge. So for every edge (x,y) not present in the MST of graph G there exist a cycle of which it is the maximum weight edge .  \\
This property will remain true even after adding the new edges from a new vertex u because all such new edges are not the part of these cycles  . So all those edges again will not be a part of the new MST by cycle property on all such cycles . 
\end{proof}


\begin{algorithm}
$\backslash \backslash $ {\tt{T(V,E) is the minimum spanning tree of the older graph}} \\
$visited[v] \leftarrow True$ \\
$dfn[v] \leftarrow count $ \\
$count \leftarrow count + 1 $ \\
$\backslash \backslash $ {\tt{u is the the new vertex added}} \\
$maxEdge \leftarrow (u,v) $ \\
$T' \leftarrow T' \cup (u,v)$ \\
\ForEach{$(v,x) \in E$ }{
    \If{$visited[x] = False$}{
    	$parent[x] \leftarrow u$ \\
    	$maxEdgeToU \leftarrow dfs(x)$ \\
    	$T' \leftarrow T' \cup {(v,x)}$ \\
    	$maxEdgeToU \leftarrow$ edge with maximum wt in $\{maxEdgeToU,(v,x)\}$ \\
    	\eIf{$wt(maxEdge) > wt(maxEdgeToU)$}{
    	$T' \leftarrow T' \backslash \{maxEdge\}$ \\
    	$maxEdge \leftarrow maxEdgeToU$
    	}
    	{
    	$T' \leftarrow T' \backslash \{maxEdgeToU\}$ \\
    	}
    	}
    }
    return $maxEdge$
\caption{\textsc{dfs(\(v\)) }}
\label{chord_intersection}
\end{algorithm}
\subsection*{Proof of Correctness :}
We are using cycle property . Maximum weight edge of a cycle is not present in the minimum spanning tree. \\
Let u be the new vertex added . We solve the problem from using the following recursive argument . \\
Whenever a dfs on vertex v terminates we have the minimum spanning tree of the graph including that subtree and vertex u . We also return the maximum weight edge on the path from v to u in that mst. We have to preserve this property during dfs.   \\
Now consider the dfs of a vertex v'. Let p be the children of v' in the old MST. 
\begin{itemize}
\item After dfs(p) is completed we have the maximum weight edge on the path from p to u , Edge (v',u) and  current maximum weight edge on the path from v' to u .
\item These edges together form a cycle so we remove the maximum weight edge of this cycle . There are essentially now two paths from v' to u and we know the maximum weight edge of both the paths . 
\item We also need to find the new maximum weight edge on the path from v' to u. One path is broken when we removed the maximum weight edge . So the new maximum weight edge is the maximum weight edge of the other path . The thing to note is now we again have exactly one path from v' to u. This  ensures that all the vertices have a path to u and hence the graph (new MST here) remains connected whenever an edge is removed.
\item Total number of edges in the new graph is (n + n-1 =) 2n -1.  Initially whenever we start a dfs on a vertex we include the edge of that vertex to u . So considering this we add total n edges . Now whenever we include an edge from the old MST we remove an edge from this such that all the vertices are still connected . This property is preserved at the end of every dfs , for an edge we add , we remove an edge . So number of edges remain n. Thus the number of edges in the new  spanning tree is n and the proof that it is indeed minimum spanning tree is from the cycle property because everytime we are removing the maximum weight edge of the a cycle. 
\end{itemize}



\pagebreak

\end{document}
